{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4efaf347-309f-432b-a2af-9c15a48ea8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ResNet in PyTorch.\n",
    "\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212310f-e1a8-4a05-9546-a281265b2156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0753b2c9-641f-487c-994a-b3bf51817e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_cifar_batch(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        batch = pickle.load(fo, encoding='bytes')\n",
    "    return batch\n",
    "\n",
    "def load_cifar_batches(files):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as fo:\n",
    "            batch = pickle.load(fo, encoding='bytes')\n",
    "        all_images.append(batch[b'data'].reshape((-1, 3, 32, 32)).astype(np.float32) / 255.0)\n",
    "        all_labels.append(batch[b'labels'])\n",
    "    return np.concatenate(all_images), np.concatenate(all_labels)\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), # Randomly flip the images on the horizontal axis\n",
    "    transforms.RandomRotation(10), # Randomly rotate the images by +/- 10 degrees\n",
    "    transforms.RandomCrop(32, padding=4), # Apply random crops\n",
    "    transforms.ToTensor(), # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalize images\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# batch_files = ['cifar-10-batches-py/data_batch_1', 'cifar-10-batches-py/data_batch_2', 'cifar-10-batches-py/data_batch_3', 'cifar-10-batches-py/data_batch_4', 'cifar-10-batches-py/data_batch_5']\n",
    "# train_images_dict, train_labels = load_cifar_batches(batch_files)\n",
    "\n",
    "# # print(len(train_images_dict))\n",
    "# train_images = train_images_dict.reshape((-1, 3, 32, 32)).astype(np.float32) / 255.0 \n",
    "# # train_labels = train_labels_dict[b'labels']\n",
    "\n",
    "# train_images_tensor = torch.tensor(train_images, dtype=torch.float32)\n",
    "# train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "# trainDataLoader = torch.utils.data.DataLoader(train_images_tensor, batch_size=64,shuffle=True)\n",
    "# trainDataLoaderLabels = torch.utils.data.DataLoader(train_labels_tensor, batch_size=64,shuffle=True)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~\n",
    "\n",
    "# batch_1_dict = load_cifar_batch('cifar-10-batches-py/data_batch_3')\n",
    "# train_images = batch_1_dict[b'data'].reshape((-1, 3, 32, 32)).astype(np.float32) / 255.0 \n",
    "# train_labels = batch_1_dict[b'labels']\n",
    "\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~\n",
    "\n",
    "batch_files = ['cifar-10-batches-py/data_batch_1', 'cifar-10-batches-py/data_batch_2', 'cifar-10-batches-py/data_batch_3', 'cifar-10-batches-py/data_batch_4', 'cifar-10-batches-py/data_batch_5']\n",
    "trainarr = None\n",
    "trainlabel = None\n",
    "\n",
    "for file in batch_files:\n",
    "    # Load CIFAR-10 batch\n",
    "    batch_data = load_cifar_batch(file)\n",
    "    \n",
    "    # Extract images and labels\n",
    "    images = batch_data[b'data']  # Assuming 'data' contains the images\n",
    "    labels = batch_data[b'labels']  # Assuming 'labels' contains the corresponding labels\n",
    "    \n",
    "    # Reshape images to (-1, 3, 32, 32) and normalize\n",
    "    images = images.reshape((-1, 3, 32, 32)).astype(np.float32) / 255.0\n",
    "    \n",
    "    # Append images and labels to trainarr and trainlabel respectively\n",
    "    if trainarr is None:\n",
    "        trainarr = images\n",
    "        trainlabel = labels\n",
    "    else:\n",
    "        trainarr = np.concatenate((trainarr, images), axis=0)\n",
    "        trainlabel = np.concatenate((trainlabel, labels), axis=0)\n",
    "\n",
    "\n",
    "train_images_tensor = torch.tensor(trainarr, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(trainlabel, dtype=torch.long)\n",
    "\n",
    "\n",
    "trainDataLoader = torch.utils.data.DataLoader(train_images_tensor, batch_size=64,shuffle=True)\n",
    "trainDataLoaderLabels = torch.utils.data.DataLoader(train_labels_tensor, batch_size=64,shuffle=True)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "\n",
    "testdata = load_cifar_batch('cifar-10-batches-py/test_batch')\n",
    "test_images = testdata[b'data'].reshape((-1, 3, 32, 32)).astype(np.float32) / 255.0 \n",
    "test_labels = testdata[b'labels']\n",
    "\n",
    "test_images_tensor = torch.tensor(test_images, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "\n",
    "testDataLoader = torch.utils.data.DataLoader(test_images_tensor, batch_size=64,shuffle=True)\n",
    "testDataLoaderLabels = torch.utils.data.DataLoader(test_labels_tensor, batch_size=64,shuffle=True)\n",
    "\n",
    "\n",
    "images = next(iter(trainDataLoader))\n",
    "labels = next(iter(trainDataLoaderLabels))\n",
    "print(len(trainDataLoader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff5f74-fec5-440e-93c0-e371ca6cdcab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9573af4-b3d9-498d-ad40-ec294fad6acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss 2.377144864148191, Test loss 2.307589204448044\n",
      "Epoch 1, Train loss 2.306876627990352, Test loss 2.3068732304178226\n",
      "Epoch 2, Train loss 2.3063747904184835, Test loss 2.304910532228506\n",
      "Epoch 3, Train loss 2.306922726009203, Test loss 2.3052359614402627\n",
      "Epoch 4, Train loss 2.3058435858972848, Test loss 2.308054509436249\n",
      "Epoch 5, Train loss 2.3064606762907998, Test loss 2.3054943707338564\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18().cuda()\n",
    "loss = torch.nn.CrossEntropyLoss() # Step 2: loss\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=.01)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "matches = 0\n",
    "total = 0\n",
    "\n",
    "# for epoch in range(3):\n",
    "#   train_loss = 0.0\n",
    "#   test_loss = 0.0\n",
    "\n",
    "#   model.train()\n",
    "#   for i, data in enumerate(zip(trainDataLoader, trainDataLoaderLabels)):\n",
    "#     images, labels = data\n",
    "#     images = images.cuda()\n",
    "#     labels = labels.cuda()\n",
    "#     optimizer.zero_grad() # zero out any gradient values from the previous iteration\n",
    "#     predicted_output = model(images) # forward propagation\n",
    "#     fit = loss(predicted_output, labels)  # calculate our measure of goodness\n",
    "#     fit.backward() # backpropagation\n",
    "#     optimizer.step() # update the weights of our trainable parameters\n",
    "#     train_loss += fit.item()\n",
    "#   train_loss = train_loss / len(trainDataLoader)\n",
    "#   train_loss_history += [train_loss]\n",
    "#   print(f'Epoch {epoch}, Train loss {train_loss}')\n",
    "\n",
    "\n",
    "for epoch in range(20):\n",
    "  train_loss = 0.0\n",
    "  test_loss = 0.0\n",
    "\n",
    "  model.train()\n",
    "  for i, data in enumerate(zip(trainDataLoader, trainDataLoaderLabels)):\n",
    "    images, labels = data\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    optimizer.zero_grad() # zero out any gradient values from the previous iteration\n",
    "    predicted_output = model(images) # forward propagation\n",
    "    fit = loss(predicted_output, labels)  # calculate our measure of goodness\n",
    "    fit.backward() # backpropagation\n",
    "    optimizer.step() # update the weights of our trainable parameters\n",
    "    train_loss += fit.item()\n",
    "\n",
    "  model.eval()\n",
    "  for i, data in  enumerate(zip(testDataLoader, testDataLoaderLabels)):\n",
    "    with torch.no_grad():\n",
    "      images, labels = data\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "      predicted_output = model(images)\n",
    "      fit = loss(predicted_output, labels)\n",
    "      test_loss += fit.item()\n",
    "      _, predicted = torch.max(predicted_output.data, 1)\n",
    "      matches += (predicted == labels).sum().item()\n",
    "      total += labels.size(0)\n",
    "  train_loss = train_loss / len(trainDataLoader)\n",
    "  test_loss = test_loss / len(testDataLoader)\n",
    "  train_loss_history += [train_loss]\n",
    "  test_loss_history += [test_loss]\n",
    "  print(f'Epoch {epoch}, Train loss {train_loss}, Test loss {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce4cdbf4-e121-4049-82c5-4fa42b87608f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 9 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "for i, data in  enumerate(zip(testDataLoader, testDataLoaderLabels)):\n",
    "  images, labels = data\n",
    "  images = images.cuda()\n",
    "  labels = labels.cuda()\n",
    "  with torch.no_grad():\n",
    "    predicted_output = model(images)\n",
    "    _, predicted = torch.max(predicted_output.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
