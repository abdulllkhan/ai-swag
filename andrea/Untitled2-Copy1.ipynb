{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af09f36-63b8-49ba-aabe-975407fc85b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "'''ResNet in PyTorch.\n",
    "\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition\n",
    "    . arXiv:1512.03385\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, prob_dropout=0.3):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # mod here\n",
    "        self.dropout1 = nn.Dropout2d(p=prob_dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "\n",
    "        # mod here\n",
    "        self.dropout2 = nn.Dropout2d(p=prob_dropout)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet9():\n",
    "    return ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "    \n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())\n",
    "\n",
    "# test()\n",
    "\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d6ac58-c558-4c91-a9d4-2954410407ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "import torch.utils.data\n",
    "from torchvision.transforms import ToTensor\n",
    "torch.manual_seed(1024)\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), # Add color jitter\n",
    "    # transforms.RandomHorizontalFlip(), #apply horizontal flipping\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(), # Randomly flip the images on the horizontal axis\n",
    "    # transforms.RandomRotation(10), # Randomly rotate the images by +/- 10 degrees\n",
    "    # transforms.RandomCrop(32, padding=4), # Apply random crops\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    # transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(), # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalize images\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Apply transformations to datasets\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "batch_size = 16\n",
    "# Create DataLoader\n",
    "trainDataLoader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testDataLoader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# for batch in train_loader:\n",
    "#     print(batch)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645b839d-674e-4dc5-9fcd-4fb6761b305b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchsummary import summary\n",
    "# from torch.optim.lr_scheduler import StepLR \n",
    "\n",
    "\n",
    "\n",
    "input_size = 28 # each input token is a row of a FashionMNIST image so 28 pixels\n",
    "hidden_size=128 # hidden representation size\n",
    "num_layers = 2  # two-layer LSTM\n",
    "num_classes = 10\n",
    "\n",
    "learning_rate= 0.01\n",
    "\n",
    "\n",
    "model = ResNet9().cuda()\n",
    "model.load_state_dict(torch.load('my_model_weights.pth'))\n",
    "loss = torch.nn.CrossEntropyLoss() # Step 2: loss\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=.001)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "# overfitting\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "# summary(model, (3, 32, 32))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be80dbf8-340f-4ca5-9a7b-3994ded324aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  4903242\n"
     ]
    }
   ],
   "source": [
    "num_epochs=40\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Number of parameters: \", num_params)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0009, momentum=0.9, weight_decay=1e-5)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)  # T_max is typically set to the number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8da2d4-8e3f-47a4-9a01-82eaed46636c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning\n",
      "epoch 0 train loss 0.365176789367497\n",
      "epoch 1 train loss 0.3562690950524807\n",
      "epoch 2 train loss 0.3420518339973688\n",
      "epoch 3 train loss 0.32744943346709016\n",
      "epoch 4 train loss 0.3154638339853287\n",
      "epoch 5 train loss 0.3090467218917608\n",
      "epoch 6 train loss 0.3025328635804355\n",
      "epoch 7 train loss 0.2962124489313364\n",
      "epoch 8 train loss 0.2793005823466182\n",
      "epoch 9 train loss 0.2698242404061556\n",
      "epoch 10 train loss 0.2629868407458067\n",
      "epoch 11 train loss 0.2528243648068607\n",
      "epoch 12 train loss 0.24331311888337134\n",
      "epoch 13 train loss 0.23593203740358354\n",
      "epoch 14 train loss 0.22670731483772397\n",
      "epoch 15 train loss 0.22336709954231979\n",
      "epoch 16 train loss 0.2139384103424102\n",
      "epoch 17 train loss 0.20325559547297656\n",
      "epoch 18 train loss 0.19667344963386654\n",
      "epoch 19 train loss 0.19106642444461583\n",
      "epoch 20 train loss 0.1855848950113356\n",
      "epoch 21 train loss 0.1787099402911961\n",
      "epoch 22 train loss 0.16860882401488722\n",
      "epoch 23 train loss 0.16119375531252472\n",
      "epoch 24 train loss 0.15679664021141826\n",
      "epoch 25 train loss 0.15089659917920828\n",
      "epoch 26 train loss 0.1411854692238569\n",
      "epoch 27 train loss 0.13783765941977502\n",
      "epoch 28 train loss 0.13512985140245407\n",
      "epoch 29 train loss 0.13099958704214543\n",
      "epoch 30 train loss 0.12703502019397914\n",
      "epoch 31 train loss 0.12214558219403028\n",
      "epoch 32 train loss 0.11856018888786435\n",
      "epoch 33 train loss 0.11711461141780019\n",
      "epoch 34 train loss 0.11438942613001912\n"
     ]
    }
   ],
   "source": [
    "total_step = len(trainDataLoader)\n",
    "\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "matches = 0\n",
    "total = 0\n",
    "print(\"beginning\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(trainDataLoader):\n",
    "  \n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # forward\n",
    "        predicted_output = model(images) # forward propagation\n",
    "        fit = loss(predicted_output, labels)  # calculate our measure of goodness\n",
    "    \n",
    "        # backwards\n",
    "        optimizer.zero_grad() # zero out any gradient values from the previous iteration\n",
    "        fit.backward() # backpropagation\n",
    "        optimizer.step() # update the weights of our trainable parameters\n",
    "        train_loss += fit.item()\n",
    "    train_loss = train_loss / len(trainDataLoader)\n",
    "    train_loss_history += [train_loss]\n",
    "    print(\"epoch \" + str(epoch) + \" train loss \" + str(train_loss))\n",
    "\n",
    "    scheduler.step()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888b1255-9ff5-496d-89d1-c74e89231674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 89.43%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    for images, labels in testDataLoader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Test accuracy: {100 * correct / total}%')\n",
    "\n",
    "# ~10 epochs = 81.5%?\n",
    "# ~13 = Test accuracy: 79.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df572a-f7d1-48eb-8920-31220f13dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PREDICTIONS\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "test_images_nl = unpickle('cifar_test_nolabels.pkl')[b'data']\n",
    "test_images_nl2 = unpickle('cifar_test_nolabels.pkl')[b'data']\n",
    "test_images_nl_id = unpickle('cifar_test_nolabels.pkl')[b'ids'].tolist()\n",
    "\n",
    "test_images_nl = test_images_nl.reshape((-1, 3, 32, 32))\n",
    "min_val = np.min(test_images_nl)\n",
    "max_val = np.max(test_images_nl)\n",
    "test_images_nl = (test_images_nl - min_val) / (max_val - min_val) #normalizing facepalm\n",
    "\n",
    "test_images_nl2 = test_images_nl2.reshape((-1, 3, 32, 32)).astype(np.float32) / 255.0\n",
    "\n",
    "# print(test_images_nl)\n",
    "# print(\"rawr\")\n",
    "# print(test_images_nl2)\n",
    "\n",
    "# plt.figure(figsize=(20, 4))\n",
    "# for i in range(10):\n",
    "#     plt.subplot(1, 10, i+1)\n",
    "#     plt.imshow(test_images_nl[i])\n",
    "#     plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "test_images_tensor_nl = torch.tensor(test_images_nl, dtype=torch.float32)\n",
    "testDataLoaderNL = torch.utils.data.DataLoader(test_images_tensor_nl, batch_size=1,shuffle=False)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "model.eval()\n",
    "for image in testDataLoaderNL:\n",
    "    image = image.cuda()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        predictions.append(output.argmax().item())\n",
    "# for image in testDataLoaderNL:\n",
    "#     image = image.cuda()\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image)\n",
    "\n",
    "#     # _, predicted_class = torch.max(output, 1)\n",
    "#     # predictions.append(predicted_class.item())\n",
    "\n",
    "#     # Preprocess the image if necessary\n",
    "#     # Perform inference\n",
    "#     # Here we assume 'resnet' is already loaded and 'image' is preprocessed\n",
    "#     output = model(image)\n",
    "#     # Perform post-processing if necessary\n",
    "#     # Append the prediction to the predictions list\n",
    "#     predictions.append(output.argmax().item())\n",
    "\n",
    "print(len(predictions))\n",
    "# # print(test_images_nl_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d6878-c6f4-4cb4-bf06-473767caf2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK ACC\n",
    "def calculate_accuracy(predictions, actual):\n",
    "    if len(predictions) != len(actual):\n",
    "        raise ValueError(\"Length of predictions and actual arrays must be the same.\")\n",
    "    \n",
    "    num_matches = sum(1 for pred, act in zip(predictions, actual) if pred == act)\n",
    "    accuracy = (num_matches / len(predictions)) * 100\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "actual = []\n",
    "pattern = [8, 2, 9, 0, 4, 3, 6, 1, 7, 5]\n",
    "for num in pattern:\n",
    "    actual.extend([num] * 1000)\n",
    "calculate_accuracy(predictions, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a39ed849-839d-4e4f-961e-dfb668854ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'betterish_my_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85adc613-7bdd-438e-8f89-600e8e995ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best = 32\n",
    "def write_lr_best_to_file(lr_best):\n",
    "    with open(\"lr_best.txt\", \"w\") as file:\n",
    "        file.write(str(lr_best))\n",
    "write_lr_best_to_file(lr_best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9f1195a-873c-4ee0-ace3-2476e3de5902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with IDs and labels\n",
    "df = pd.DataFrame({\n",
    "    'ID': test_images_nl_id,\n",
    "    'Labels': predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fd62d18-8752-42d3-b7ff-20f2365457d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 84 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "for i, data in  enumerate(test_loader):\n",
    "  images, labels = data\n",
    "  images = images.cuda()\n",
    "  labels = labels.cuda()\n",
    "  with torch.no_grad():\n",
    "    predicted_output = model(images)\n",
    "    _, predicted = torch.max(predicted_output.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cfed886-203d-4979-ad19-0054c5b8e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "test_images_nl = unpickle('cifar_test_nolabels.pkl')[b'data']\n",
    "test_images_nl_id = unpickle('cifar_test_nolabels.pkl')[b'ids'].tolist()\n",
    "\n",
    "test_images_nl = test_images_nl.reshape((-1, 3, 32, 32)).astype(np.float32) / 255.0\n",
    "\n",
    "test_images_tensor_nl = torch.tensor(test_images_nl, dtype=torch.float32)\n",
    "\n",
    "testDataLoaderNL = torch.utils.data.DataLoader(test_images_tensor_nl, batch_size=1,shuffle=True)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for image in testDataLoaderNL:\n",
    "    image = image.cuda()\n",
    "    # Preprocess the image if necessary\n",
    "    # Perform inference\n",
    "    # Here we assume 'resnet' is already loaded and 'image' is preprocessed\n",
    "    output = model(image)\n",
    "    # Perform post-processing if necessary\n",
    "    # Append the prediction to the predictions list\n",
    "    predictions.append(output.argmax().item())\n",
    "\n",
    "# print(len(predictions))\n",
    "# print(test_images_nl_id)\n",
    "\n",
    "# Create a DataFrame with IDs and labels\n",
    "df = pd.DataFrame({\n",
    "    'ID': test_images_nl_id,\n",
    "    'Labels': predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('predictions.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
